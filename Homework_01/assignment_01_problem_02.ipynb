{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 align=\"right\">by <a href=\"http://cse.iitkgp.ac.in/~adas/\">Abir Das</a> with help of <br> Ram Rakesh and Ankit Singh<br> </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the following details here\n",
    "** Name: ** `<WRITE YOUR NAME HERE>`<br/>\n",
    "** Roll Number: ** `<WRITE YOUR ROLL NUMBER HERE>`<br/>\n",
    "** Department: ** `<WRITE YOUR DEPARTMENT HERE>`<br/>\n",
    "** Email: ** `<WRITE YOUR EMAIL ID HERE>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "To run and solve this assignment, one must have a working IPython Notebook installation. The easiest way to set it up for both Windows and Linux is to install [Anaconda](https://www.continuum.io/downloads). Then save this file ([`assignment_01.ipynb`]()) to your computer, run Anaconda and choose this file in Anaconda's file explorer. Use `Python 3` version. Below statements assume that you have already followed these instructions. If you are new to Python or its scientific library, Numpy, there are some nice tutorials [here](https://www.learnpython.org/) and [here](http://www.scipy-lectures.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: You will implement a fully connected neural network from scratch in this problem\n",
    "We marked places where you are expected to add/change your own code with **`##### write your code below #####`** comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "597wDiAvGvuB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "'''You are not supposed to import any other python library to work on this assignments.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "B54oZmm1DNWe",
    "outputId": "8c59bd48-230d-4fb9-eba1-82471de363df"
   },
   "outputs": [],
   "source": [
    "'''data is loaded from data directory.\n",
    "please don't remove the folder '''\n",
    "\n",
    "x_train = np.load('./data/X_train.npy')\n",
    "x_train = x_train.flatten().reshape(-1,28*28)\n",
    "x_train = x_train / 255.0\n",
    "gt_indices = np.load('./data/y_train.npy')\n",
    "train_length = len(x_train)\n",
    "print(\"Number of training examples: {:d}\".format(train_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LvVFhXNB5xrD"
   },
   "outputs": [],
   "source": [
    "'''Dimensions to be used for creating your model'''\n",
    "\n",
    "batch_size = 64  # batch size\n",
    "input_dim = 784  # input dimension\n",
    "hidden_1_dim = 512  # hidden layer 1 dimension\n",
    "hidden_2_dim = 256  # hidden layer 2 dimension\n",
    "output_dim = 10   # output dimension\n",
    "\n",
    "'''Other hyperparameters'''\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hImaaujc5zXg"
   },
   "outputs": [],
   "source": [
    "#creating one hot vector representation of output classification\n",
    "y_train = np.zeros((train_length, output_dim))\n",
    "# print(y.shape, gt_indices.shape)\n",
    "for i in range(train_length):\n",
    "    y_train[i,gt_indices[i]] = 1\n",
    "\n",
    "# Number of mini-batches (as integer) in one epoch\n",
    "num_minibatches = np.floor(train_length/batch_size).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W7lHWEWVaVlK",
    "outputId": "4ecb1bfc-4568-44cb-e109-57677da50eb7"
   },
   "outputs": [],
   "source": [
    "print(\"No of mini-batches {:d} and total training data used in training:\\\n",
    "{}.\".format(num_minibatches, num_minibatches*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "C9HRf0Wj52cK"
   },
   "outputs": [],
   "source": [
    "'''Randomly Initialize Weights  from standard normal distribution (i.e., mean = 0 and s.d. = 1.0).\n",
    "Use the dimesnions specified in the cell 3 to initialize your weights matrices. \n",
    "Use the nomenclature W1,W2 etc. (provided below) for the different weight matrices.'''\n",
    "\n",
    "########################## write your code below ##############################################\n",
    "W1 = \n",
    "W2 = \n",
    "W3 = \n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PmZRrEVb6CJy"
   },
   "outputs": [],
   "source": [
    "# Write a function which computes the softmax where X is vector of scores computed during forward pass\n",
    "def softmax(x):\n",
    "    ##############################write your code here #################################\n",
    "    \n",
    "    \n",
    "    ####################################################################################\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "Gjz4yhwE6JQw",
    "outputId": "341578db-29a4-48ca-b0f8-a0343aadd24b"
   },
   "outputs": [],
   "source": [
    "no_of_iterations = 20000\n",
    "loss_list=[]\n",
    "i_epoch = 0\n",
    "for i_iter in range(no_of_iterations):\n",
    "    \n",
    "    ''''''\n",
    "    batch_elem_idx = i_iter%num_minibatches\n",
    "    x_batchinput = x_train[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size]\n",
    "    \n",
    "    ########################## write your code below ##############################################\n",
    "    ######################### Forward Pass Block #####################################\n",
    "    '''Write the code for forward block of the neural network with 2 hidden layers.\n",
    "    Please stick to the notation below which follows the notation provided in the lecture slides.\n",
    "    Note that you are allowed to write the right hand sides of these variables in more than\n",
    "    one line if that is convenient for you.'''\n",
    "    \n",
    "    # first hidden layer implementation\n",
    "    a1 =\n",
    "    # implement Relu layer\n",
    "    h1 = \n",
    "    #  implement 2 hidden layer\n",
    "    a2 = \n",
    "    # implement Relu activation \n",
    "    h2 = \n",
    "    #implement linear output layer\n",
    "    a3 = \n",
    "    # softmax layer\n",
    "    softmax_score = softmax(a3) #enusre you have implemented the softmax function defined above\n",
    "    ##################################################################################\n",
    "    ###############################################################################################\n",
    "\n",
    "    neg_log_softmax_score = -np.log(softmax_score+0.00000001) # The small number is added to avoid 0 input to log function\n",
    "    \n",
    "    # Compute and print loss\n",
    "    if i_iter%num_minibatches == 0:\n",
    "        loss = np.mean(np.diag(np.take(neg_log_softmax_score, gt_indices[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size],\\\n",
    "                                       axis=1)))\n",
    "        print(\" Epoch: {:d}, iteration: {:d}, Loss: {:6.4f} \".format(i_epoch, i_iter, loss))\n",
    "        loss_list.append(loss)\n",
    "        i_epoch += 1\n",
    "        # Each 10th epoch reduce learning rate by a factor of 10\n",
    "        if i_epoch%10 == 0:\n",
    "            learning_rate /= 10.0\n",
    "     \n",
    "    ################################### Backpropagation Code Block #####################################\n",
    "    ''' Use the convention grad_{} for computing the gradients.\n",
    "    for e.g \n",
    "        grad_W1 for gradients w.r.t. weight W1\n",
    "        grad_w2 for gradients w.r.t. weights W2'''\n",
    "    ########################## write your code below ##############################################\n",
    "    # Gradient of cross-entropy loss w.r.t. preactivation of the output layer\n",
    "    grad_softmax_score = \n",
    "    \n",
    "    # gradient w.r.t W3\n",
    "    grad_W3 = \n",
    "    # gradient w.r.t h2\n",
    "    grad_h2 = \n",
    "    # gradient w.r.t a2\n",
    "    grad_a2 = \n",
    "    # gradient w.r.t W2\n",
    "    grad_W2 = \n",
    "    # gradient w.r.t h1\n",
    "    grad_h1 = \n",
    "    # gradient w.r.t a1\n",
    "    grad_a1 = \n",
    "    # gradient w.r.t W1\n",
    "    grad_W1 = \n",
    "    ###############################################################################################\n",
    "    ####################################################################################################\n",
    "    \n",
    "    \n",
    "    ################################ Update Weights Block using SGD ####################################\n",
    "    W3 -= learning_rate * grad_W3\n",
    "    W2 -= learning_rate * grad_W2\n",
    "    W1 -= learning_rate * grad_W1\n",
    "    ####################################################################################################\n",
    "    \n",
    "#plotting the loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(loss_list)\n",
    "plt.title('Loss vs epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Loading the test data from data/X_test.npy and data/y_test.npy.'''\n",
    "x_test = np.load('./data/X_test.npy')\n",
    "x_test = x_test.flatten().reshape(-1,28*28)\n",
    "x_test = x_test / 255.0\n",
    "y_test = np.load('./data/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_test = 100 # Deliberately taken 100 so that it divides the test data size\n",
    "num_minibatches = len(y_test)/batch_size_test\n",
    "test_correct = 0\n",
    "\n",
    "'''Only forward block code and compute softmax_score .'''\n",
    "for i_iter in range(int(num_minibatches)):\n",
    "    \n",
    "    '''Get one minibatch'''\n",
    "    batch_elem_idx = i_iter%num_minibatches\n",
    "    x_batchinput = x_test[i_iter*batch_size_test:(i_iter+1)*batch_size_test]\n",
    "    \n",
    "    ######### copy only the forward pass block of your code and pass the x_batchinput to it and compute softmax_score ##########\n",
    "    # first hidden layer implementation\n",
    "    a1 =\n",
    "    # implement Relu layer\n",
    "    h1 =\n",
    "    #  implement 2nd hidden layer\n",
    "    a2 =\n",
    "    # implement Relu activation \n",
    "    h2 =\n",
    "    #implement linear output layer\n",
    "    a3 =\n",
    "    # softmax layer\n",
    "    softmax_score = softmax(a3) #enusre you have implemented the softmax function defined above\n",
    "    ##################################################################################\n",
    "    \n",
    "    y_batchinput = y_test[i_iter*batch_size_test:(i_iter+1)*batch_size_test]\n",
    "    \n",
    "    y_pred = np.argmax(softmax_score, axis=1)\n",
    "    num_correct_i_iter = np.sum(y_pred == y_batchinput)\n",
    "    test_correct += num_correct_i_iter\n",
    "print (\"Test accuracy is {:4.2f} %\".format(test_correct/len(y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_Hidden_MLP_New.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
